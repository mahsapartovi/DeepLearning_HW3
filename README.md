This assignment aims to develop a question-answering model based on the BERT architecture, to generate concise answers for given input questions. The model will input a question in text format and output a brief, relevant answer.
The implementation leverages the Spoken-SQuAD dataset for training (The model is trained on a provided dataset containing 37,111 question-answer pairs for training and 5,351 pairs for testing, formatted in JSON files) 
and employs a structured approach using Python, CUDA, and libraries such as PyTorch, Transformers, numpy, scipy, pickle, and pandas to enable efficient training and evaluation

These results imply that the training process improved the model's ability to handle the task, achieving more balanced and accurate predictions as it evolved.

